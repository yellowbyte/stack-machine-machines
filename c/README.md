Different languages force a programmer to think about computation in a different way. For example, in Racket everything is an expression, or in Python everything is an object. C also forces programmer to think in a particular way about computation. What differ between C and most other languages is that the computational model C confines programmers in is one that matches reality (i.e., the hardware the program is executed on). 

The C language specification, in a sense, is incomplete; it only defines a subset of the possible C semantics. The part that is not defined is called _undefined behaviors_ where there is no guarantees how the program will behave if it reaches those dark corners. Perhaps at the time it makes sense since it relieves some burden off the compiler developers: compiler only has to implement the core semantics, for the other semantics that users should not trigger, the compiler can implement it however it wants. The problem is that this dark corner of C is too easily reached and ventured by too many. As time has shown, various software vulnerabilities have manifest in C programs where they are not possible in others. Although one can say that the errors that can manifest in C programs are solely due to the C programmers' oversight. In other languages with a computational model differing from the underlying machine, errors can manifest in the implementation of the computational model abstraction. For example, although Java frees programmers from pointers errors (e.g., null pointer dereference, double free), the JVM itself itself riddled with pointer errors. 
